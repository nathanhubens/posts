---
keywords: fastai
description: How to find winning tickets in your neural network
title: Winning the Lottery with fastai
toc: true
badges: false
categories: [Deep Learning]
comments: true
image: images/pruning.png
hide: true
nb_path: _notebooks/2020-12-10-Lottery-2.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-12-10-Lottery-2.ipynb
-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Lottery-Ticket-Hypothesis"><strong>Lottery Ticket Hypothesis</strong><a class="anchor-link" href="#Lottery-Ticket-Hypothesis"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The Lottery Ticket Hypothesis is a fascinating characteristic of neural networks that has been found by Frankle and Carbin in 2019. The hypothesis is the following: in a neural network, there exists a subnetwork that can be trained to a comparable accuracy and in a comparable training time than the whole network. The only condition is that the subnetwork starts from the same initial condition than when it was part of the whole network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In practice, this subnetwork, called "winning ticket", can be found by using pruning on the network, removing useless connections.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The steps to isolate this winning ticket are:</p>
<ol>
<li>Get a freshly initialized network</li>
<li>Train it to convergence</li>
<li>Prune the smallest weights, i.e. the weights that possess the lowest $l_1$-norm</li>
<li>Reinitialize the remaining weights to their original value, i.e. their value at step 1)</li>
<li>Repeat</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/posts/images/copied_from_nb/images/LTH/test2.gif" alt="Alt Text"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using fasterai, we already know how to prune a network. The only change here is that we have to keep track of initialization since we want to start from the initial conditions each time.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the original paper, the idea was to iteratively prune the network, resetting the remaining weights to their initial value after each pruning step.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Sparsifier</span><span class="p">():</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">granularity</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">layer_type</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">store_attr</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save_weights</span><span class="p">()</span> <span class="c1"># Save the original weights</span>

    <span class="k">def</span> <span class="nf">prune_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">granularity</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_mask</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">,</span> <span class="n">round_to</span><span class="p">)</span>
        <span class="n">m</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_mask&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="c1"># Put the mask into a buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prune_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="o">=</span><span class="kc">None</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_type</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">prune_layer</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">,</span> <span class="n">round_to</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">&quot;_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">granularity</span> <span class="o">==</span> <span class="s1">&#39;filter&#39;</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> <span class="c1"># We want to prune the bias when pruning filters</span>

    <span class="k">def</span> <span class="nf">_mask_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;_mask&#39;</span><span class="p">):</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">&quot;_mask&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">granularity</span> <span class="o">==</span> <span class="s1">&#39;filter&#39;</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_reset_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1"># Reset non-pruned weights</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">):</span>
                <span class="n">init_weights</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">&quot;_init_weights&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">init_biases</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">&quot;_init_biases&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">init_biases</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">batchnorm</span><span class="o">.</span><span class="n">_BatchNorm</span><span class="p">):</span> <span class="n">m</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_init_weights&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                <span class="n">b</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_init_biases&quot;</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_clean_buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;_mask&#39;</span><span class="p">):</span> <span class="k">del</span> <span class="n">m</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="s2">&quot;_mask&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;_init_weights&#39;</span><span class="p">):</span> <span class="k">del</span> <span class="n">m</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="s2">&quot;_init_weights&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;_init_biases&#39;</span><span class="p">):</span> <span class="k">del</span> <span class="n">m</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="s2">&quot;_init_biases&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_compute_threshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;global&#39;</span><span class="p">:</span>
            <span class="n">global_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">granularity</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_type</span><span class="p">)])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">global_weight</span><span class="p">,</span> <span class="n">sparsity</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span> <span class="c1"># Compute the threshold globally (only once per model pruning)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;local&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">sparsity</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span> <span class="c1"># Compute the threshold locally</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">NameError</span><span class="p">(</span><span class="s1">&#39;Invalid Method&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_rounded_sparsity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_to_prune</span><span class="p">,</span> <span class="n">round_to</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">round_to</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_to_prune</span><span class="o">/</span><span class="n">round_to</span><span class="p">),</span> <span class="n">round_to</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_compute_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">,</span> <span class="n">round_to</span><span class="p">):</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_threshold</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">round_to</span><span class="p">:</span>
            <span class="n">n_to_keep</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">threshold</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rounded_sparsity</span><span class="p">(</span><span class="n">n_to_keep</span><span class="p">,</span> <span class="n">round_to</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">threshold</span> <span class="o">&gt;</span> <span class="n">weight</span><span class="o">.</span><span class="n">max</span><span class="p">():</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="c1"># Make sure we don&#39;t remove every weight of a given layer</span>
        <span class="k">return</span> <span class="n">weight</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">print_sparsity</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_type</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sparsity in </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span><span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SparsifyCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">end_sparsity</span><span class="p">,</span> <span class="n">granularity</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">sched_func</span><span class="p">,</span> <span class="n">start_sparsity</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lth</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rewind_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reset_end</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer_type</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">store_attr</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_sparsity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">previous_sparsity</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="o">&gt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">rewind_epoch</span><span class="p">,</span> <span class="s1">&#39;You must rewind to an epoch before the start of the pruning process&#39;</span>

    <span class="k">def</span> <span class="nf">before_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Pruning of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">granularity</span><span class="si">}</span><span class="s1"> until a sparsity of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">end_sparsity</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_epoch</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_epoch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_epoch</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_epoch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_epoch</span><span class="p">,</span> <span class="s1">&#39;Your end_epoch must be smaller than total number of epoch&#39;</span>

        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="c1"># Pass a model if you don&#39;t want the whole model to be pruned</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparsifier</span> <span class="o">=</span> <span class="n">Sparsifier</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">granularity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">criteria</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">bs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_iters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span>

    <span class="k">def</span> <span class="nf">before_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewind_epoch</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Saving Weights at epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sparsifier</span><span class="o">.</span><span class="n">_save_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">before_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="o">&gt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_epoch</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_sparsity</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sparsifier</span><span class="o">.</span><span class="n">prune_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_sparsity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">round_to</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lth</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_sparsity</span><span class="o">!=</span><span class="bp">self</span><span class="o">.</span><span class="n">previous_sparsity</span><span class="p">:</span> <span class="c1"># If sparsity has changed, the network has been pruned</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Resetting Weights to their epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rewind_epoch</span><span class="si">}</span><span class="s1"> values&#39;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sparsifier</span><span class="o">.</span><span class="n">_reset_weights</span><span class="p">()</span>
                    <span class="c1">#self.sparsifier.model = resnet18(num_classes=10)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">previous_sparsity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_sparsity</span>

    <span class="k">def</span> <span class="nf">before_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="o">&gt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sparsifier</span><span class="o">.</span><span class="n">_mask_grad</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">after_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Sparsity at the end of epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">current_sparsity</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">after_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Final Sparsity: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">current_sparsity</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_end</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sparsifier</span><span class="o">.</span><span class="n">_reset_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparsifier</span><span class="o">.</span><span class="n">_clean_buffers</span><span class="p">()</span> <span class="c1"># Remove buffers at the end of training</span>
        <span class="c1">#self.sparsifier.print_sparsity()</span>

    <span class="k">def</span> <span class="nf">_set_sparsity</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_sparsity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sched_func</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">start_sparsity</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">end_sparsity</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_iter</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">start_iter</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_iters</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">start_iter</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's first get our baseline:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">initial_weights</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.536754</td>
      <td>1.709699</td>
      <td>0.481529</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.254531</td>
      <td>1.314451</td>
      <td>0.578089</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.116412</td>
      <td>1.168404</td>
      <td>0.634904</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.023481</td>
      <td>1.156428</td>
      <td>0.633376</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.946494</td>
      <td>0.998459</td>
      <td>0.677962</td>
      <td>00:11</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;All keys matched successfully&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In fasterai,</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sp_cb</span> <span class="o">=</span> <span class="n">SparsifyCallback</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;global&#39;</span><span class="p">,</span> <span class="n">large_final</span><span class="p">,</span> <span class="n">iterative</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lth</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">sp_cb</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Pruning of weight until a sparsity of 50%
Saving Weights at epoch 0
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.541520</td>
      <td>1.568734</td>
      <td>0.501911</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.258532</td>
      <td>1.628220</td>
      <td>0.508790</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.111838</td>
      <td>1.292680</td>
      <td>0.596688</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.024304</td>
      <td>1.385538</td>
      <td>0.581146</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.930883</td>
      <td>1.041547</td>
      <td>0.672102</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.330930</td>
      <td>1.395270</td>
      <td>0.520510</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.141437</td>
      <td>1.135004</td>
      <td>0.620637</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.040761</td>
      <td>1.267395</td>
      <td>0.581656</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.952175</td>
      <td>1.272328</td>
      <td>0.594650</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.909871</td>
      <td>1.207141</td>
      <td>0.629554</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>10</td>
      <td>1.235558</td>
      <td>1.197264</td>
      <td>0.598217</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>11</td>
      <td>1.042131</td>
      <td>1.067109</td>
      <td>0.658854</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.927392</td>
      <td>0.977499</td>
      <td>0.673376</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.888816</td>
      <td>0.916399</td>
      <td>0.699873</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.800480</td>
      <td>0.774320</td>
      <td>0.743439</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>15</td>
      <td>1.052142</td>
      <td>1.027188</td>
      <td>0.665223</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.921996</td>
      <td>0.945266</td>
      <td>0.694268</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.831712</td>
      <td>0.868593</td>
      <td>0.717452</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.812539</td>
      <td>1.016729</td>
      <td>0.673376</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.764737</td>
      <td>0.859072</td>
      <td>0.725860</td>
      <td>00:19</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sparsity at the end of epoch 0: 0.00%
Sparsity at the end of epoch 1: 0.00%
Sparsity at the end of epoch 2: 0.00%
Sparsity at the end of epoch 3: 0.00%
Sparsity at the end of epoch 4: 0.00%
Resetting Weights to their epoch 0 values
Sparsity at the end of epoch 5: 16.67%
Sparsity at the end of epoch 6: 16.67%
Sparsity at the end of epoch 7: 16.67%
Sparsity at the end of epoch 8: 16.67%
Sparsity at the end of epoch 9: 16.67%
Resetting Weights to their epoch 0 values
Sparsity at the end of epoch 10: 33.33%
Sparsity at the end of epoch 11: 33.33%
Sparsity at the end of epoch 12: 33.33%
Sparsity at the end of epoch 13: 33.33%
Sparsity at the end of epoch 14: 33.33%
Resetting Weights to their epoch 0 values
Sparsity at the end of epoch 15: 50.00%
Sparsity at the end of epoch 16: 50.00%
Sparsity at the end of epoch 17: 50.00%
Sparsity at the end of epoch 18: 50.00%
Sparsity at the end of epoch 19: 50.00%
Final Sparsity: 50.00
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;All keys matched successfully&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sp_cb</span> <span class="o">=</span> <span class="n">SparsifyCallback</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;global&#39;</span><span class="p">,</span> <span class="n">large_final</span><span class="p">,</span> <span class="n">iterative</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lth</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rewind_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">sp_cb</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Pruning of weight until a sparsity of 50%
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.529935</td>
      <td>1.430763</td>
      <td>0.522548</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.268891</td>
      <td>1.251196</td>
      <td>0.603822</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.141558</td>
      <td>1.176961</td>
      <td>0.626497</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.013069</td>
      <td>1.312681</td>
      <td>0.607134</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.933651</td>
      <td>0.914163</td>
      <td>0.695796</td>
      <td>00:11</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.183302</td>
      <td>1.339694</td>
      <td>0.553121</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.027278</td>
      <td>1.148169</td>
      <td>0.634904</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.919856</td>
      <td>1.031522</td>
      <td>0.672866</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.890848</td>
      <td>0.910739</td>
      <td>0.713885</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.824205</td>
      <td>0.932853</td>
      <td>0.697580</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>10</td>
      <td>1.054473</td>
      <td>1.329592</td>
      <td>0.585987</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.947696</td>
      <td>1.136064</td>
      <td>0.637452</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.852863</td>
      <td>0.820551</td>
      <td>0.731210</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.794559</td>
      <td>1.009437</td>
      <td>0.673631</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.775261</td>
      <td>0.844786</td>
      <td>0.721529</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.933353</td>
      <td>1.198227</td>
      <td>0.640000</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.846583</td>
      <td>0.898716</td>
      <td>0.715669</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.789335</td>
      <td>0.781211</td>
      <td>0.741656</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.745516</td>
      <td>1.174927</td>
      <td>0.637962</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.705972</td>
      <td>0.786245</td>
      <td>0.751847</td>
      <td>00:20</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sparsity at the end of epoch 0: 0.00%
Saving Weights at epoch 1
Sparsity at the end of epoch 1: 0.00%
Sparsity at the end of epoch 2: 0.00%
Sparsity at the end of epoch 3: 0.00%
Sparsity at the end of epoch 4: 0.00%
Resetting Weights to their epoch 1 values
Sparsity at the end of epoch 5: 16.67%
Sparsity at the end of epoch 6: 16.67%
Sparsity at the end of epoch 7: 16.67%
Sparsity at the end of epoch 8: 16.67%
Sparsity at the end of epoch 9: 16.67%
Resetting Weights to their epoch 1 values
Sparsity at the end of epoch 10: 33.33%
Sparsity at the end of epoch 11: 33.33%
Sparsity at the end of epoch 12: 33.33%
Sparsity at the end of epoch 13: 33.33%
Sparsity at the end of epoch 14: 33.33%
Resetting Weights to their epoch 1 values
Sparsity at the end of epoch 15: 50.00%
Sparsity at the end of epoch 16: 50.00%
Sparsity at the end of epoch 17: 50.00%
Sparsity at the end of epoch 18: 50.00%
Sparsity at the end of epoch 19: 50.00%
Final Sparsity: 50.00
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_sparsity</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sparsity in Conv2d 1: 41.28%
Sparsity in Conv2d 7: 25.14%
Sparsity in Conv2d 10: 25.66%
Sparsity in Conv2d 13: 25.76%
Sparsity in Conv2d 16: 25.46%
Sparsity in Conv2d 20: 33.97%
Sparsity in Conv2d 23: 34.10%
Sparsity in Conv2d 26: 12.82%
Sparsity in Conv2d 29: 34.61%
Sparsity in Conv2d 32: 33.99%
Sparsity in Conv2d 36: 43.95%
Sparsity in Conv2d 39: 44.27%
Sparsity in Conv2d 42: 18.27%
Sparsity in Conv2d 45: 43.93%
Sparsity in Conv2d 48: 43.33%
Sparsity in Conv2d 52: 54.12%
Sparsity in Conv2d 55: 54.15%
Sparsity in Conv2d 58: 24.68%
Sparsity in Conv2d 61: 54.24%
Sparsity in Conv2d 64: 51.93%
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>That's all! Thank you for reading, I hope that you'll like FasterAI. I do not claim that it is perfect, you'll probably find a lot of bugs. If you do, just please tell me, so I can try to solve them  </strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p style="font-size: 15px"><i>If you notice any mistake or improvement that can be done, please contact me ! If you found that post useful, please consider citing it as:</i></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>@article{hubens2020fasterai,
  title   = "Winning the Lottery with fastai",
  author  = "Hubens, Nathan",
  journal = "nathanhubens.github.io",
  year    = "2020",
  url     = "https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html"
}</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References"><strong>References</strong><a class="anchor-link" href="#References"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>{{'<a href="https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf">Cristian Bucilu, Rich Caruana, and Alexandru Niculescu-Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, 2006</a>' | fndetail: 1}}</li>
<li>{{'<a href="https://arxiv.org/abs/1911.04252">Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V. Le: Self-training with Noisy Student improves ImageNet classification. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020</a>' | fndetail: 2}}</li>
<li>{{'<a href="http://cs230.stanford.edu/files_winter_2018/projects/6940224.pdf">H. Li, "Exploring knowledge distillation of Deep neural nets for efficient hardware solutions," CS230 Report, 2018</a>' | fndetail: 3}}</li>
<li>{{'<a href="https://openreview.net/pdf?id=Sy1iIDkPM">Zhu, M. &amp; Gupta, S. (2017). To prune, or not to prune: exploring the efficacy of pruning for model compression. ICLR, 2018 </a>' | fndetail: 4}}</li>
</ul>

</div>
</div>
</div>
</div>
 

