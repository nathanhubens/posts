<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>FasterAI | Nathan Hubens</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="FasterAI" />
<meta name="author" content="" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How to make your network smaller and faster with the use of fastai library" />
<meta property="og:description" content="How to make your network smaller and faster with the use of fastai library" />
<link rel="canonical" href="https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html" />
<meta property="og:url" content="https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html" />
<meta property="og:site_name" content="Nathan Hubens" />
<meta property="og:image" content="https://nathanhubens.github.io/posts/images/pruning.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-17T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":""},"description":"How to make your network smaller and faster with the use of fastai library","@type":"BlogPosting","headline":"FasterAI","url":"https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html","datePublished":"2020-08-17T00:00:00-05:00","dateModified":"2020-08-17T00:00:00-05:00","image":"https://nathanhubens.github.io/posts/images/pruning.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/posts/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nathanhubens.github.io/posts/feed.xml" title="Nathan Hubens" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-164628236-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/posts/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>FasterAI | Nathan Hubens</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="FasterAI" />
<meta name="author" content="" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How to make your network smaller and faster with the use of fastai library" />
<meta property="og:description" content="How to make your network smaller and faster with the use of fastai library" />
<link rel="canonical" href="https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html" />
<meta property="og:url" content="https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html" />
<meta property="og:site_name" content="Nathan Hubens" />
<meta property="og:image" content="https://nathanhubens.github.io/posts/images/pruning.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-17T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":""},"description":"How to make your network smaller and faster with the use of fastai library","@type":"BlogPosting","headline":"FasterAI","url":"https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html","datePublished":"2020-08-17T00:00:00-05:00","dateModified":"2020-08-17T00:00:00-05:00","image":"https://nathanhubens.github.io/posts/images/pruning.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://nathanhubens.github.io/posts/feed.xml" title="Nathan Hubens" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-164628236-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
<script src="https://d3js.org/d3.v4.min.js"></script>
  <script src="https://d3js.org/d3-scale-chromatic.v1.min.js"></script>
  
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/posts/">Nathan Hubens</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/posts/search/">Search</a><a class="page-link" href="/posts/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">FasterAI</h1><p class="page-description">How to make your network smaller and faster with the use of fastai library</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-08-17T00:00:00-05:00" itemprop="datePublished">
        Aug 17, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      16 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/posts/categories/#Deep Learning">Deep Learning</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introducing-FasterAI">Introducing FasterAI </a></li>
<li class="toc-entry toc-h2"><a href="#Knowledge-Distillation">Knowledge Distillation </a></li>
<li class="toc-entry toc-h2"><a href="#Sparsifying">Sparsifying </a></li>
<li class="toc-entry toc-h2"><a href="#Pruning">Pruning </a></li>
<li class="toc-entry toc-h2"><a href="#Batch-Normalization-Folding">Batch Normalization Folding </a></li>
<li class="toc-entry toc-h2"><a href="#FC-Layers-Factorization">FC Layers Factorization </a></li>
<li class="toc-entry toc-h2"><a href="#References">References </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-17-FasterAI.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p style="font-size: 15px"><i>The code is available <a href="https://github.com/nathanhubens/fasterai">here</a></i></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introducing-FasterAI">
<a class="anchor" href="#Introducing-FasterAI" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Introducing FasterAI</strong><a class="anchor-link" href="#Introducing-FasterAI"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>FasterAI</strong> is a project that I started to make my <strong>smaller</strong> and <strong>faster</strong> with the use of the <a href="https://github.com/fastai/fastai">fastai</a> library. The techniques implemented here can easily be used with plain Pytorch but the idea was to express them in an abstract and easy-to-use  manner (à la fastai).</p>
<p>In this article, we'll explain how to use FasterAI by going through an example use-case.</p>
<p><br></p>
<blockquote>
<p><strong>Ready ? Let's dive in then !</strong></p>
</blockquote>
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's start with a bit of context for the purpose of the demonstration. Imagine that we want to deploy a <strong>VGG16</strong> model on a mobile device that has limited storage capacity and that our task requires our model to run sufficiently fast. It is known that parameters and speed efficiency are not the strong points of <strong>VGG16</strong> but let's see what we can do with it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's first check the number of parameters and the inference time of <strong>VGG16</strong>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16_bn</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, <strong>VGG16</strong> has <strong>134</strong> millions of parameters</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total parameters : 134,309,962
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And takes <strong>4.03ms</strong> to perform inference on a single image.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>4.03 ms ± 18.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Snap ! This is more than we can afford for deployment, ideally we would like our model to take only half of that...but should we give up ? Nope, there are actually a lot of techniques that we can use to help reducing the size and improve the speed of our models! Let's see how to apply them with <strong>FasterAI</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will first train our <strong>VGG16</strong> model to have a <strong>baseline</strong> of what performance we should expect from it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.016354</td>
      <td>1.778865</td>
      <td>0.368917</td>
      <td>01:31</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.777570</td>
      <td>1.508860</td>
      <td>0.523567</td>
      <td>01:31</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.436139</td>
      <td>1.421571</td>
      <td>0.569172</td>
      <td>01:32</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.275864</td>
      <td>1.118840</td>
      <td>0.630064</td>
      <td>01:31</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.136620</td>
      <td>0.994999</td>
      <td>0.687898</td>
      <td>01:31</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.970474</td>
      <td>0.824344</td>
      <td>0.739618</td>
      <td>01:31</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.878756</td>
      <td>0.764273</td>
      <td>0.765605</td>
      <td>01:32</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.817084</td>
      <td>0.710727</td>
      <td>0.781911</td>
      <td>01:31</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.716041</td>
      <td>0.625853</td>
      <td>0.804841</td>
      <td>01:31</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.668815</td>
      <td>0.605727</td>
      <td>0.810955</td>
      <td>01:31</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we would like our network to have comparable accuracy but fewer parameters and running faster... And the first technique that we will show how to use is called <strong>Knowledge Distillation</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Knowledge-Distillation">
<a class="anchor" href="#Knowledge-Distillation" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Knowledge Distillation</strong><a class="anchor-link" href="#Knowledge-Distillation"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Knowledge distillation is a simple yet very efficient way to train a model. It was introduced in 2006 by <a href="https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf">Caruana et al.</a><sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup>. The main idea behind is to use a small model (called the <strong>student</strong>) to approximate the function learned by a larger and high-performing model (called the <strong>teacher</strong>). This can be done by using the large model to pseudo-label the data. This idea has been used very recently to <a href="https://arxiv.org/abs/1911.04252">break the state-of-the-art accuracy on ImageNet</a><sup id="fnref-2" class="footnote-ref"><a href="#fn-2">2</a></sup>.</p>
<p>When we train our model for classification, we usually use a softmax as last layer. This softmax has the particularity to squish low value logits towards <strong>0</strong>, and the highest logit towards <strong>1</strong>. This has for effect to completely lose all the inter-class information, or what is sometimes called the <em>dark knowledge</em>. This is the information that is valuable and that we want to transfer from the teacher to the student.</p>
<p>To do so, we still use a regular classification loss but at the same time, we'll use another loss, computed between the <em>softened</em> logits of the teacher (our <em>soft labels</em>) and the <em>softened</em> logits of the student (our <em>soft predictions</em>). Those soft values are obtained when you use a <strong>soft-softmax</strong>, that avoids squishing the values at its output. Our implementation follows <a href="http://cs230.stanford.edu/files_winter_2018/projects/6940224.pdf">this paper</a><sup id="fnref-3" class="footnote-ref"><a href="#fn-3">3</a></sup> and the basic principle of training is represented in the figure below:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/posts/images/copied_from_nb/images/fasterai/KD.png" alt="" style="max-width: 600px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To use <strong>Knowledge Distillation</strong> with FasterAI, you only need to use this callback when training your student model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<blockquote>
<pre><b><i> KnowledgeDistillation(student:Learner, teacher:Learner) </i></b></pre>
<p style="font-size: 15px"><i>
You only need to give to the callback function your student learner and your teacher learner. Behind the scenes, FasterAI will take care of making your model train using knowledge distillation.
</i></p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first thing to do is to find a teacher, which can be any model, that preferrably performs well. We will chose <strong>VGG19</strong> for our demonstration. To make sure it performs better than our <strong>VGG16</strong> model, let's start from a pretrained version.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg19_bn</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">teacher</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.249884</td>
      <td>0.088749</td>
      <td>0.972739</td>
      <td>01:02</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.201829</td>
      <td>0.087495</td>
      <td>0.974268</td>
      <td>01:02</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.261882</td>
      <td>0.082631</td>
      <td>0.974013</td>
      <td>01:01</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our teacher has <strong>97.4%</strong> of accuracy which is pretty good, it is ready to take a student under its wing. So let's create our student model and train it with the <strong>Knowledge Distillation</strong> callback:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16_bn</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">student</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">KnowledgeDistillation</span><span class="p">(</span><span class="n">student</span><span class="p">,</span> <span class="n">teacher</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.323744</td>
      <td>2.102873</td>
      <td>0.410955</td>
      <td>02:16</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.099557</td>
      <td>2.441147</td>
      <td>0.571465</td>
      <td>02:16</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.829197</td>
      <td>2.215419</td>
      <td>0.607643</td>
      <td>02:16</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.617705</td>
      <td>1.683477</td>
      <td>0.667006</td>
      <td>02:16</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.364808</td>
      <td>1.366435</td>
      <td>0.713376</td>
      <td>02:16</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.257906</td>
      <td>0.985063</td>
      <td>0.788025</td>
      <td>02:16</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.087404</td>
      <td>0.877424</td>
      <td>0.801019</td>
      <td>02:17</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.949960</td>
      <td>0.777630</td>
      <td>0.822166</td>
      <td>02:16</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.868683</td>
      <td>0.733206</td>
      <td>0.837707</td>
      <td>02:17</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.756630</td>
      <td>0.707806</td>
      <td>0.843057</td>
      <td>02:16</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we can see that indeed, the knowledge of the teacher was useful for the student, as it is clearly overperforming the vanilla <strong>VGG16</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, so now we are able to get more from a given model which is kind of cool ! With some experimentations we could come up with a model smaller than <strong>VGG16</strong> but able to reach the same performance as our baseline! You can try to find it by yourself later, but for now let's continue with the next technique !</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sparsifying">
<a class="anchor" href="#Sparsifying" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Sparsifying</strong><a class="anchor-link" href="#Sparsifying"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a student model that is performing better than our baseline, we have some room to compress it. And we'll start by making the network sparse. As explained in a previous <a href="https://nathanhubens.github.io/posts/deep%20learning/2020/05/22/pruning.html">article</a>, there are many ways leading to a sparse network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>Usually, the process of making a network sparse is called Pruning. I prefer using the term Pruning when parameters are <strong>actually</strong> removed from the network, which we will do in the next section. 
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br>
<figure>
  
    <img class="docimage" src="/posts/images/copied_from_nb/images/pruning/schedules.png" alt="" style="max-width: 680px">
    
    
</figure>

<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default, FasterAI uses the <strong>Automated Gradual Pruning</strong> paradigm as it removes parameters as the model trains and doesn't require to pretrain the model, so it is usually much faster. In FasterAI, this is also managed by using a callback, that will replace the <em>least important</em> parameters of your model by zeroes during the training. The callback has a wide variety of parameters to tune your <strong>Sparsifying</strong> operation, let's take a look at them:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
    <pre><b><i>SparsifyCallback(learn, sparsity, granularity, method, criteria, sched_func)</i></b></pre>

<ul><i>
<li style="font-size:15px">
<b>sparsity</b>: the percentage of sparsity that you want in your network </li>
<li style="font-size:15px">
<b>granularity</b>: on what granularity you want the sparsification to be operated (currently supported: <code>weight</code>, <code>filter</code>)</li>
<li style="font-size:15px">
<b>method</b>: either <code>local</code> or <code>global</code>, will affect the selection of parameters to be choosen in each layer independently (<code>local</code>) or on the whole network (<code>global</code>).</li>
<li style="font-size:15px">
<b>criteria</b>: the criteria used to select which parameters to remove (currently supported: <code>l1</code>, <code>taylor</code>)</li>
<li style="font-size:15px">
<b>sched_func</b>: which schedule you want to follow for the sparsification (currently supported: <a href="https://docs.fast.ai/callback.html#Annealing-functions">any scheduling function of fastai</a>, i.e <code>annealing_linear</code>, <code>annealing_cos</code>, ... and <code>annealing_gradual</code>, the schedule proposed by <a href="https://openreview.net/pdf?id=Sy1iIDkPM">Zhu &amp; Gupta</a><sup id="fnref-4" class="footnote-ref"><a href="#fn-4">4</a></sup>, represented in Figure below)</li>
</i></ul>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/posts/images/copied_from_nb/images/pruning/gradual.png" alt="" style="max-width: 500px">
    
    
</figure>

<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Although I found that <strong>Automated Gradual Pruning</strong> usually works best, you may want to use the other paradigms. They can easily be achieved by doing:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p><strong>One-Shot Pruning</strong></p>
<div class="highlight"><pre><span></span><span class="n">sparsifier</span> <span class="o">=</span> <span class="n">Sparsifier</span><span class="p">(</span><span class="n">granularity</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">criteria</span><span class="p">)</span>
<span class="n">new_model</span> <span class="o">=</span> <span class="n">sparsifier</span><span class="o">.</span><span class="n">prune</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">)</span>
</pre></div>
</blockquote>
<p></p>
<p style="font-size:15px">To perform <b>One-Shot Pruning</b>, you can simply prune your model to the desired sparsity. This is probably highly suboptimal as removing parameters will shake up the model and hurt it quite a bit.
</p>
<br>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p><strong>Iterative Pruning</strong></p>
<div class="highlight"><pre><span></span><span class="n">new_model</span> <span class="o">=</span> <span class="n">sparsifier</span><span class="o">.</span><span class="n">prune</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">new_model</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">SparsifyCallback</span><span class="p">(</span><span class="n">learn</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">,</span> <span class="n">granularity</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">criteria</span><span class="p">,</span> <span class="n">sched_func</span><span class="o">=</span><span class="n">annealing_no</span><span class="p">)])</span>
<span class="n">sparsity</span> <span class="o">+=</span> <span class="n">increase_value</span>
<span class="c1"># REPEAT</span>
</pre></div>
</blockquote>
<p style="font-size:15px">    To perform <b>Iterative Pruning</b>, we first need to train our model, then perform several iterations of pruning and fine-tuning until desired sparsity. Fine-tuning has to be done with <code>SparsifyCallback</code> and the <code>annealing_no</code> schedule to ensure our zero-weights don't get updated.
</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>But let's come back to our example!</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, we will make our network <strong>40%</strong> sparse, and remove entire <strong>filters</strong>, selected <strong>locally</strong> and based on <strong>L1 norm</strong>. We will train with a learning rate a bit smaller to be gentle with our network because it has already been trained. The <strong>scheduling</strong> selected is cosinusoidal, so the pruning starts and ends quite slowly.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">SparsifyCallback</span><span class="p">(</span><span class="n">student</span><span class="p">,</span> <span class="n">sparsity</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">'filter'</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'local'</span><span class="p">,</span> <span class="n">criteria</span><span class="o">=</span><span class="s1">'l1'</span><span class="p">,</span> <span class="n">sched_func</span><span class="o">=</span><span class="n">annealing_cos</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Pruning of filter until a sparsity of 40%
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.584072</td>
      <td>0.532074</td>
      <td>0.838471</td>
      <td>01:34</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.583805</td>
      <td>0.499353</td>
      <td>0.844586</td>
      <td>01:34</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.599410</td>
      <td>0.527805</td>
      <td>0.836433</td>
      <td>01:34</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.610081</td>
      <td>0.544566</td>
      <td>0.828025</td>
      <td>01:35</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.625637</td>
      <td>0.543279</td>
      <td>0.829809</td>
      <td>01:34</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.628777</td>
      <td>0.563051</td>
      <td>0.819618</td>
      <td>01:34</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.688617</td>
      <td>0.617627</td>
      <td>0.800000</td>
      <td>01:34</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.691044</td>
      <td>0.629927</td>
      <td>0.801019</td>
      <td>01:34</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.669935</td>
      <td>0.576220</td>
      <td>0.814013</td>
      <td>01:33</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.682428</td>
      <td>0.562718</td>
      <td>0.823949</td>
      <td>01:34</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sparsity at epoch 0: 0.98%
Sparsity at epoch 1: 3.83%
Sparsity at epoch 2: 8.25%
Sparsity at epoch 3: 13.83%
Sparsity at epoch 4: 20.01%
Sparsity at epoch 5: 26.19%
Sparsity at epoch 6: 31.76%
Sparsity at epoch 7: 36.19%
Sparsity at epoch 8: 39.02%
Sparsity at epoch 9: 40.00%
Final Sparsity: 40.00
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our network now has <strong>40%</strong> of its filters composed entirely of zeroes, at the cost of <strong>2%</strong> of accuracy. Obviously, choosing a higher sparsity, makes it more difficult for the network to keep a similar accuracy. Other parameters can also widely change the behaviour of our sparsification process. For example choosing a more fine-grained sparsity usually leads to better results but is then more difficult to take advantage of in terms of speed.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can double-check that our model has indeed been pruned by <strong>40%</strong> of its parameters.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sparsity in Conv2d 2: 39.06%
Sparsity in Conv2d 5: 39.06%
Sparsity in Conv2d 9: 39.84%
Sparsity in Conv2d 12: 39.84%
Sparsity in Conv2d 16: 39.84%
Sparsity in Conv2d 19: 39.84%
Sparsity in Conv2d 22: 39.84%
Sparsity in Conv2d 26: 39.84%
Sparsity in Conv2d 29: 39.84%
Sparsity in Conv2d 32: 39.84%
Sparsity in Conv2d 36: 39.84%
Sparsity in Conv2d 39: 39.84%
Sparsity in Conv2d 42: 39.84%
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We don't have <strong>exactly 40%</strong> because, as we removed complete filters, we don't necesserally have a round number.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now see how much we gained in terms of speed. Because we removed <strong>40%</strong> of convolution filters, we should expect crazy speed-up right ?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>4.02 ms ± 5.77 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Well actually, no. We didn't remove any parameters, we just replaced some by zeroes, remember? The amount of parameters is still the same:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total parameters : 134,309,962
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Which leads us to the next section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pruning">
<a class="anchor" href="#Pruning" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Pruning</strong><a class="anchor-link" href="#Pruning"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>This is currently only supported for fully-feedforward models such as VGG-like models as more complex architectures require increasingly difficult and usually model-dependant implementations.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Why don't we see any acceleration even though we removed half of the parameters? That's because natively, our <strong>GPU</strong> does not know that our matrices are sparse and thus isn't able to accelerate the computation. The easiest work around, is to <strong>physically</strong> remove the parameters we zeroed-out. But this operation requires to change the architecture of the network.</p>
<p>This pruning only works if we have zeroed-out entire filters beforehand as it is the only case where you can change the architecture accordingly. Hopefully, sparse computations will <a href="https://pytorch.org/docs/stable/sparse.html">soon be available</a> on common deep learning librairies so this section will become useless in the future, but for the moment, it is the best solution I could come up with 🤷</p>
<p><br></p>
<p>Here is what it looks like with fasterai:
<br></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<pre><b><i>pruner = Pruner()
pruned_model = pruner.prune_model(learn.model)</i></b></pre>
<p style="font-size: 15px"><i>
You just need to pass the model whose filters has previously been sparsified and FasterAI will take care of removing them.
</i></p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>This operation should be lossless as it only removes filters that already do not participate in the network anymore.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So in the case of our example, it gives:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pruner</span> <span class="o">=</span> <span class="n">Pruner</span><span class="p">()</span>
<span class="n">pruned_model</span> <span class="o">=</span> <span class="n">pruner</span><span class="o">.</span><span class="n">prune_model</span><span class="p">(</span><span class="n">student</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now see what our model is capable of now:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total parameters : 83,975,344
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And in terms of speed:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2.44 ms ± 3.51 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Yay ! Now we can talk ! Let's just double check that our accuracy is unchanged and that we didn't mess up somewhere:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.5641388, tensor(0.8229)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And there is actually more that we can do ! Let's keep going !</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Batch-Normalization-Folding">
<a class="anchor" href="#Batch-Normalization-Folding" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Batch Normalization Folding</strong><a class="anchor-link" href="#Batch-Normalization-Folding"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Batch Normalization Folding</strong> is a really easy to implement and straightforward idea. The gist is that batch normalization is nothing more than a normalization of the input data at each layer. Moreover, at inference time, the batch statistics used for this normalization are fixed. We can thus incorporate the normalization process directly in the convolution by changing its weights and completely remove the batch normalization layers, which is a gain both in terms of parameters and in terms of computations. For a more in-depth explaination, see my <a href="https://nathanhubens.github.io/posts/deep%20learning/2020/04/20/BN.html">previous post</a>.</p>
<p>This is how to use it with FasterAI:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<pre><b><i>bn_folder = BN_Folder()
bn_folder.fold(learn.model))</i></b></pre>
<p style="font-size: 15px"><i>
Again, you only need to pass your model and FasterAI takes care of the rest. For models built using the nn.Sequential, you don't need to change anything. For others, if you want to see speedup and compression, you actually need to subclass your model to remove the batch norm from the parameters and from the <code>forward</code> method of your network.
</i></p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>This operation should also be lossless as it redefines the convolution to take batch norm into account and is thus equivalent.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's do this with our model !</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">folded_model</span> <span class="o">=</span> <span class="n">bn_folding_model</span><span class="p">(</span><span class="n">pruned_learner</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The parameters drop is generally not that significant, especially in a network such as <strong>VGG</strong> where almost all parameters are contained in the FC layers but, hey, any gain is good to take.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total parameters : 83,970,260
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we removed the batch normalization layers, we should again see a speedup.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2.27 ms ± 1.22 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, let's double check that we didn't mess up somewhere:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.5641388, tensor(0.8229)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we're still not done yet ! As we know for <strong>VGG16</strong>, most of the parameters are comprised in the fully-connected layers so there should be something that we can do about it, right ?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FC-Layers-Factorization">
<a class="anchor" href="#FC-Layers-Factorization" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>FC Layers Factorization</strong><a class="anchor-link" href="#FC-Layers-Factorization"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can indeed, factorize our big fully-connected layers and replace them by an approximation of two smaller layers. The idea is to make an <strong>SVD</strong> decomposition of the weight matrix, which will express the original matrix in a product of 3 matrices: $U \Sigma V^T$. With $\Sigma$ being a diagonal matrix with non-negative values along its diagonal (the singular values). We then define a value $k$ of singular values to keep and modify matrices $U$ and $V^T$ accordingly. The resulting will be an approximation of the initial matrix.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/posts/images/copied_from_nb/images/fasterai/svd.png" alt="" style="max-width: 600px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In FasterAI, to decompose the fully-connected layers of your model, here is what you need to do:
<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<pre><b><i>FCD = FCDecomposer()
decomposed_model = FCD.decompose(model, percent_removed)</i></b></pre>
<p style="font-size: 15px"><i>
    The <code>percent_removed</code> corresponds to the percentage of singular values removed (<i>k</i> value above).
</i></p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>This time, the decomposition is not exact, so we expect a drop in performance afterwards and further retraining will be needed.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Which gives with our example, if we only want to keep half of them:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fc_decomposer</span> <span class="o">=</span> <span class="n">FCDecomposer</span><span class="p">()</span>
<span class="n">decomposed_model</span> <span class="o">=</span> <span class="n">fc_decomposer</span><span class="o">.</span><span class="n">decompose</span><span class="p">(</span><span class="n">folded_model</span><span class="p">,</span> <span class="n">percent_removed</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How many parameters do we have now ?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total parameters : 61,430,022
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And how much time did we gain ?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2.11 ms ± 462 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>However, this technique is an approximation so it is not lossless, so we should retrain our network a bit to recover its performance.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">final_learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">decomposed_model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">final_learner</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.795416</td>
      <td>0.759886</td>
      <td>0.772994</td>
      <td>00:51</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.752566</td>
      <td>0.701141</td>
      <td>0.794395</td>
      <td>00:52</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.700373</td>
      <td>0.650178</td>
      <td>0.804841</td>
      <td>00:51</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.604264</td>
      <td>0.606801</td>
      <td>0.821656</td>
      <td>00:51</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.545705</td>
      <td>0.592318</td>
      <td>0.823185</td>
      <td>00:52</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This operation is usually less useful for more recent architectures as they usually do not have that many parameters in their fully-connected layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So to recap, we saw in this article how to use fasterai to:</p>
<ol>
<li>Make a student model learn from a teacher model (<strong>Knowledge Distillation</strong>)</li>
<li>Make our network sparse (<strong>Sparsifying</strong>)</li>
<li>Optionnaly physically remove the zero-filters (<strong>Pruning</strong>)</li>
<li>Remove the batch norm layers (<strong>Batch Normalization Folding</strong>)</li>
<li>Approximate our big fully-connected layers by smaller ones (<strong>Fully-Connected Layers Factorization</strong>)</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we saw that by applying those, we could reduce our <strong>VGG16</strong> model from <strong>134 million</strong> of parameters down to <strong>61 million</strong>, and also speed-up the inference from <strong>4.03ms</strong> to <strong>2.11ms</strong> without any drop in accuracy (even a slight increase actually) compared to the baseline.</p>
<p>Of course, those techniques can be used in conjunction with <a href="https://pytorch.org/docs/stable/quantization.html">quantization</a> or <a href="https://pytorch.org/docs/stable/notes/amp_examples.html">mixed-precision training</a>, which are already available in Pytorch for even more compression and speedup.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>Please keep in mind that the techniques presented above are not magic 🧙‍♂️, so do not expect to see a 200% speedup and compression everytime. What you can achieve highly depend on the architecture that you are using (some are already speed/parameter efficient by design) or the task it is doing (some datasets are so easy that you can remove almost all your network without seeing a drop in performance)
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>That's all! Thank you for reading, I hope that you'll like FasterAI. I do not claim that it is perfect, you'll probably find a lot of bugs. If you do, just please tell me, so I can try to solve them 😌 </strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p style="font-size: 15px"><i>If you notice any mistake or improvement that can be done, please contact me ! If you found that post useful, please consider citing it as:</i></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>@article{hubens2020fasterai,
  title   = "FasterAI",
  author  = "Hubens, Nathan",
  journal = "nathanhubens.github.io",
  year    = "2020",
  url     = "https://nathanhubens.github.io/posts/deep%20learning/2020/08/17/FasterAI.html"
}</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>References</strong><a class="anchor-link" href="#References"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><div class="footnotes"><p id="fn-1">1. <a href="https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf">Cristian Buciluǎ, Rich Caruana, and Alexandru Niculescu-Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, 2006</a><a href="#fnref-1" class="footnote footnotes">↩</a></p></div></li>
<li><div class="footnotes"><p id="fn-2">2. <a href="https://arxiv.org/abs/1911.04252">Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V. Le: Self-training with Noisy Student improves ImageNet classification. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020</a><a href="#fnref-2" class="footnote footnotes">↩</a></p></div></li>
<li><div class="footnotes"><p id="fn-3">3. <a href="http://cs230.stanford.edu/files_winter_2018/projects/6940224.pdf">H. Li, "Exploring knowledge distillation of Deep neural nets for efficient hardware solutions," CS230 Report, 2018</a><a href="#fnref-3" class="footnote footnotes">↩</a></p></div></li>
<li><div class="footnotes"><p id="fn-4">4. <a href="https://openreview.net/pdf?id=Sy1iIDkPM">Zhu, M. &amp; Gupta, S. (2017). To prune, or not to prune: exploring the efficacy of pruning for model compression. ICLR, 2018 </a><a href="#fnref-4" class="footnote footnotes">↩</a></p></div></li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="/posts"
        issue-term="title"
        label="blogpost-comment"
        theme="icy-dark"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/posts/deep%20learning/2020/08/17/FasterAI.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/posts/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/posts/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/posts/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name"></li>
          <li><a class="u-email" href="mailto:nathan.hubens@gmail.com">nathan.hubens@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/nathanhubens" title="nathanhubens"><svg class="svg-icon grey"><use xlink:href="/posts/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/HubensN" title="HubensN"><svg class="svg-icon grey"><use xlink:href="/posts/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
